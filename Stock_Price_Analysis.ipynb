{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb7f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PH√ÇN T√çCH D·ªÆ LI·ªÜU CH·ª®NG KHO√ÅN V·ªöI PYSPARK\n",
    "# Stock Price Big Data Analysis\n",
    "# =============================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Import th∆∞ vi·ªán v√† kh·ªüi t·∫°o Spark Session\n",
    "\n",
    "# %%\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Thi·∫øt l·∫≠p style cho matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ ƒê√£ import c√°c th∆∞ vi·ªán th√†nh c√¥ng\")\n",
    "\n",
    "# %%\n",
    "# T·∫°o Spark Session k·∫øt n·ªëi v·ªõi Spark Master\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Stock Price Big Data Analysis\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.cores.max\", \"8\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark Session ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o\")\n",
    "print(f\"üìä Spark Version: {spark.version}\")\n",
    "print(f\"üéØ Application ID: {spark.sparkContext.applicationId}\")\n",
    "print(f\"üîó Master: {spark.sparkContext.master}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. ƒê·ªçc d·ªØ li·ªáu t·ª´ HDFS\n",
    "\n",
    "# %%\n",
    "# ƒê·ªãnh nghƒ©a schema cho d·ªØ li·ªáu\n",
    "stock_schema = StructType([\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Open\", DoubleType(), True),\n",
    "    StructField(\"High\", DoubleType(), True),\n",
    "    StructField(\"Low\", DoubleType(), True),\n",
    "    StructField(\"Close\", DoubleType(), True),\n",
    "    StructField(\"Volume\", LongType(), True)\n",
    "])\n",
    "\n",
    "# ƒê·ªçc t·∫•t c·∫£ file CSV t·ª´ HDFS\n",
    "hdfs_path = \"hdfs://namenode:9000/datack/*.csv\"\n",
    "print(f\"üìÇ ƒê·ªçc d·ªØ li·ªáu t·ª´: {hdfs_path}\")\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(stock_schema) \\\n",
    "    .csv(hdfs_path)\n",
    "\n",
    "# Th√™m c·ªôt Symbol t·ª´ t√™n file\n",
    "df = df.withColumn(\"filename\", input_file_name())\n",
    "df = df.withColumn(\"Symbol\", regexp_extract(col(\"filename\"), r\"data-(\\w+)_\", 1))\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi Date sang timestamp\n",
    "df = df.withColumn(\"Date\", to_date(col(\"Date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Cache data ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω\n",
    "df.cache()\n",
    "\n",
    "print(f\"\\n‚úÖ ƒê√£ ƒë·ªçc th√†nh c√¥ng {df.count():,} d√≤ng d·ªØ li·ªáu\")\n",
    "print(f\"üìä S·ªë l∆∞·ª£ng c·ªï phi·∫øu: {df.select('Symbol').distinct().count()}\")\n",
    "\n",
    "# %%\n",
    "# Xem c·∫•u tr√∫c d·ªØ li·ªáu\n",
    "print(\"\\nüìã C·∫§U TR√öC D·ªÆ LI·ªÜU:\")\n",
    "print(\"=\" * 80)\n",
    "df.printSchema()\n",
    "\n",
    "print(\"\\nüìã D·ªÆ LI·ªÜU M·∫™U:\")\n",
    "print(\"=\" * 80)\n",
    "df.show(10)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Th·ªëng k√™ m√¥ t·∫£\n",
    "\n",
    "# %%\n",
    "print(\"\\nüìä TH·ªêNG K√ä M√î T·∫¢\")\n",
    "print(\"=\" * 80)\n",
    "df.select(\"Open\", \"High\", \"Low\", \"Close\", \"Volume\").describe().show()\n",
    "\n",
    "# %%\n",
    "# Ph·∫°m vi th·ªùi gian d·ªØ li·ªáu\n",
    "date_range = df.agg(\n",
    "    min(\"Date\").alias(\"Start_Date\"),\n",
    "    max(\"Date\").alias(\"End_Date\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"\\nüìÖ Ph·∫°m vi th·ªùi gian:\")\n",
    "print(f\"   T·ª´: {date_range['Start_Date']}\")\n",
    "print(f\"   ƒê·∫øn: {date_range['End_Date']}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Ph√¢n t√≠ch bi·∫øn ƒë·ªông gi√°\n",
    "\n",
    "# %%\n",
    "# T√≠nh to√°n c√°c ch·ªâ s·ªë k·ªπ thu·∫≠t\n",
    "df_analysis = df.withColumn(\"Daily_Return\", (col(\"Close\") - col(\"Open\")) / col(\"Open\") * 100)\n",
    "df_analysis = df_analysis.withColumn(\"Price_Range\", col(\"High\") - col(\"Low\"))\n",
    "df_analysis = df_analysis.withColumn(\"Volatility\", (col(\"High\") - col(\"Low\")) / col(\"Open\") * 100)\n",
    "\n",
    "# T√≠nh Moving Average 7 ng√†y v√† 30 ng√†y\n",
    "window_7 = Window.partitionBy(\"Symbol\").orderBy(\"Date\").rowsBetween(-6, 0)\n",
    "window_30 = Window.partitionBy(\"Symbol\").orderBy(\"Date\").rowsBetween(-29, 0)\n",
    "\n",
    "df_analysis = df_analysis.withColumn(\"MA_7\", avg(\"Close\").over(window_7))\n",
    "df_analysis = df_analysis.withColumn(\"MA_30\", avg(\"Close\").over(window_30))\n",
    "\n",
    "print(\"\\n‚úÖ ƒê√£ t√≠nh to√°n xong c√°c ch·ªâ s·ªë k·ªπ thu·∫≠t\")\n",
    "print(\"\\nüìä D·ªÆ LI·ªÜU SAU KHI PH√ÇN T√çCH:\")\n",
    "print(\"=\" * 80)\n",
    "df_analysis.select(\"Symbol\", \"Date\", \"Close\", \"Daily_Return\", \"MA_7\", \"MA_30\").show(10)\n",
    "\n",
    "# %%\n",
    "# TOP 10 c·ªï phi·∫øu c√≥ gi√° ƒë√≥ng c·ª≠a cao nh·∫•t\n",
    "print(\"\\nüí∞ TOP 10 C·ªî PHI·∫æU GI√Å CAO NH·∫§T\")\n",
    "print(\"=\" * 80)\n",
    "top_expensive = df.groupBy(\"Symbol\") \\\n",
    "    .agg(max(\"Close\").alias(\"Max_Price\")) \\\n",
    "    .orderBy(desc(\"Max_Price\")) \\\n",
    "    .limit(10)\n",
    "top_expensive.show()\n",
    "\n",
    "# %%\n",
    "# TOP 10 c·ªï phi·∫øu c√≥ kh·ªëi l∆∞·ª£ng giao d·ªãch cao nh·∫•t\n",
    "print(\"\\nüìà TOP 10 C·ªî PHI·∫æU KH·ªêI L∆Ø·ª¢NG GIAO D·ªäCH CAO NH·∫§T\")\n",
    "print(\"=\" * 80)\n",
    "top_volume = df.groupBy(\"Symbol\") \\\n",
    "    .agg(sum(\"Volume\").alias(\"Total_Volume\")) \\\n",
    "    .orderBy(desc(\"Total_Volume\")) \\\n",
    "    .limit(10)\n",
    "top_volume.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Ph√¢n t√≠ch xu h∆∞·ªõng th·ªã tr∆∞·ªùng\n",
    "\n",
    "# %%\n",
    "# T√≠nh t·ªïng gi√° tr·ªã giao d·ªãch theo nƒÉm\n",
    "df_yearly = df.withColumn(\"Year\", year(\"Date\")) \\\n",
    "    .withColumn(\"Trade_Value\", col(\"Close\") * col(\"Volume\")) \\\n",
    "    .groupBy(\"Year\") \\\n",
    "    .agg(\n",
    "        sum(\"Trade_Value\").alias(\"Total_Trade_Value\"),\n",
    "        sum(\"Volume\").alias(\"Total_Volume\"),\n",
    "        avg(\"Close\").alias(\"Avg_Price\")\n",
    "    ) \\\n",
    "    .orderBy(\"Year\")\n",
    "\n",
    "print(\"\\nüìä PH√ÇN T√çCH THEO NƒÇM\")\n",
    "print(\"=\" * 80)\n",
    "df_yearly.show()\n",
    "\n",
    "# %%\n",
    "# Tr·ª±c quan h√≥a xu h∆∞·ªõng theo nƒÉm\n",
    "yearly_pd = df_yearly.toPandas()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('PH√ÇN T√çCH XU H∆Ø·ªöNG TH·ªä TR∆Ø·ªúNG THEO NƒÇM', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Gi√° tr·ªã giao d·ªãch\n",
    "axes[0, 0].plot(yearly_pd['Year'], yearly_pd['Total_Trade_Value'], marker='o', linewidth=2)\n",
    "axes[0, 0].set_title('T·ªïng Gi√° Tr·ªã Giao D·ªãch', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('NƒÉm')\n",
    "axes[0, 0].set_ylabel('Gi√° tr·ªã (USD)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Kh·ªëi l∆∞·ª£ng giao d·ªãch\n",
    "axes[0, 1].plot(yearly_pd['Year'], yearly_pd['Total_Volume'], marker='s', color='green', linewidth=2)\n",
    "axes[0, 1].set_title('T·ªïng Kh·ªëi L∆∞·ª£ng Giao D·ªãch', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('NƒÉm')\n",
    "axes[0, 1].set_ylabel('Kh·ªëi l∆∞·ª£ng')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Gi√° trung b√¨nh\n",
    "axes[1, 0].plot(yearly_pd['Year'], yearly_pd['Avg_Price'], marker='^', color='orange', linewidth=2)\n",
    "axes[1, 0].set_title('Gi√° Trung B√¨nh', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('NƒÉm')\n",
    "axes[1, 0].set_ylabel('Gi√° (USD)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bi·ªÉu ƒë·ªì t·ªïng h·ª£p\n",
    "axes[1, 1].bar(yearly_pd['Year'], yearly_pd['Total_Trade_Value'], alpha=0.7)\n",
    "axes[1, 1].set_title('Bi·ªÉu ƒê·ªì C·ªôt Gi√° Tr·ªã Giao D·ªãch', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('NƒÉm')\n",
    "axes[1, 1].set_ylabel('Gi√° tr·ªã (USD)')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ ƒê√£ v·∫Ω bi·ªÉu ƒë·ªì ph√¢n t√≠ch theo nƒÉm\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Ph√¢n t√≠ch c·ªï phi·∫øu c·ª• th·ªÉ\n",
    "\n",
    "# %%\n",
    "# Ch·ªçn m·ªôt s·ªë c·ªï phi·∫øu n·ªïi ti·∫øng ƒë·ªÉ ph√¢n t√≠ch chi ti·∫øt\n",
    "selected_stocks = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA']\n",
    "\n",
    "# L·ªçc d·ªØ li·ªáu\n",
    "df_selected = df_analysis.filter(col(\"Symbol\").isin(selected_stocks)) \\\n",
    "    .orderBy(\"Symbol\", \"Date\")\n",
    "\n",
    "print(f\"\\nüìå Ph√¢n t√≠ch {len(selected_stocks)} c·ªï phi·∫øu: {', '.join(selected_stocks)}\")\n",
    "print(f\"üìä T·ªïng s·ªë d√≤ng d·ªØ li·ªáu: {df_selected.count():,}\")\n",
    "\n",
    "# %%\n",
    "# Chuy·ªÉn sang Pandas ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì\n",
    "df_selected_pd = df_selected.select(\"Symbol\", \"Date\", \"Close\", \"MA_7\", \"MA_30\").toPandas()\n",
    "\n",
    "# V·∫Ω bi·ªÉu ƒë·ªì gi√° c·ªï phi·∫øu\n",
    "fig, axes = plt.subplots(len(selected_stocks), 1, figsize=(16, 4*len(selected_stocks)))\n",
    "fig.suptitle('BI·ªÇU ƒê·ªí GI√Å C·ªî PHI·∫æU V√Ä MOVING AVERAGE', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, stock in enumerate(selected_stocks):\n",
    "    stock_data = df_selected_pd[df_selected_pd['Symbol'] == stock].sort_values('Date')\n",
    "    \n",
    "    if len(stock_data) > 0:\n",
    "        ax = axes[idx] if len(selected_stocks) > 1 else axes\n",
    "        \n",
    "        ax.plot(stock_data['Date'], stock_data['Close'], label='Close Price', linewidth=1.5, alpha=0.8)\n",
    "        ax.plot(stock_data['Date'], stock_data['MA_7'], label='MA 7', linewidth=1, alpha=0.7)\n",
    "        ax.plot(stock_data['Date'], stock_data['MA_30'], label='MA 30', linewidth=1, alpha=0.7)\n",
    "        \n",
    "        ax.set_title(f'{stock} - Gi√° ƒê√≥ng C·ª≠a v√† Moving Average', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Ng√†y')\n",
    "        ax.set_ylabel('Gi√° (USD)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ ƒê√£ v·∫Ω bi·ªÉu ƒë·ªì gi√° c·ªï phi·∫øu\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Ph√¢n t√≠ch t∆∞∆°ng quan\n",
    "\n",
    "# %%\n",
    "# T√≠nh ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c c·ªï phi·∫øu\n",
    "# Pivot data ƒë·ªÉ c√≥ gi√° ƒë√≥ng c·ª≠a c·ªßa t·ª´ng c·ªï phi·∫øu theo ng√†y\n",
    "df_pivot = df_selected.groupBy(\"Date\").pivot(\"Symbol\").agg(first(\"Close\"))\n",
    "\n",
    "# Chuy·ªÉn sang Pandas ƒë·ªÉ t√≠nh correlation\n",
    "df_corr_pd = df_pivot.toPandas().set_index('Date')\n",
    "correlation_matrix = df_corr_pd.corr()\n",
    "\n",
    "print(\"\\nüîó MA TR·∫¨N T∆Ø∆†NG QUAN GI·ªÆA C√ÅC C·ªî PHI·∫æU\")\n",
    "print(\"=\" * 80)\n",
    "print(correlation_matrix)\n",
    "\n",
    "# %%\n",
    "# V·∫Ω heatmap t∆∞∆°ng quan\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('MA TR·∫¨N T∆Ø∆†NG QUAN GI·ªÆA C√ÅC C·ªî PHI·∫æU', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ ƒê√£ v·∫Ω heatmap t∆∞∆°ng quan\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Ph√¢n t√≠ch r·ªßi ro v√† l·ª£i nhu·∫≠n\n",
    "\n",
    "# %%\n",
    "# T√≠nh to√°n ch·ªâ s·ªë r·ªßi ro v√† l·ª£i nhu·∫≠n\n",
    "risk_return = df_analysis.groupBy(\"Symbol\").agg(\n",
    "    avg(\"Daily_Return\").alias(\"Avg_Return\"),\n",
    "    stddev(\"Daily_Return\").alias(\"Risk_StdDev\"),\n",
    "    min(\"Daily_Return\").alias(\"Min_Return\"),\n",
    "    max(\"Daily_Return\").alias(\"Max_Return\")\n",
    ").orderBy(desc(\"Avg_Return\"))\n",
    "\n",
    "print(\"\\n‚öñÔ∏è PH√ÇN T√çCH R·ª¶I RO V√Ä L·ª¢I NHU·∫¨N\")\n",
    "print(\"=\" * 80)\n",
    "risk_return.show(20)\n",
    "\n",
    "# %%\n",
    "# Bi·ªÉu ƒë·ªì Risk-Return\n",
    "risk_return_pd = risk_return.toPandas()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(risk_return_pd['Risk_StdDev'], risk_return_pd['Avg_Return'], \n",
    "            s=100, alpha=0.6, c=range(len(risk_return_pd)), cmap='viridis')\n",
    "\n",
    "# Th√™m label cho m·ªôt s·ªë ƒëi·ªÉm n·ªïi b·∫≠t\n",
    "for idx in range(min(10, len(risk_return_pd))):\n",
    "    plt.annotate(risk_return_pd.iloc[idx]['Symbol'], \n",
    "                (risk_return_pd.iloc[idx]['Risk_StdDev'], \n",
    "                 risk_return_pd.iloc[idx]['Avg_Return']),\n",
    "                fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.xlabel('R·ªßi Ro (ƒê·ªô l·ªách chu·∫©n)', fontsize=12)\n",
    "plt.ylabel('L·ª£i Nhu·∫≠n Trung B√¨nh (%)', fontsize=12)\n",
    "plt.title('BI·ªÇU ƒê·ªí R·ª¶I RO - L·ª¢I NHU·∫¨N', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ ƒê√£ v·∫Ω bi·ªÉu ƒë·ªì r·ªßi ro-l·ª£i nhu·∫≠n\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Ph√¢n t√≠ch kh·ªëi l∆∞·ª£ng giao d·ªãch\n",
    "\n",
    "# %%\n",
    "# Ph√¢n t√≠ch kh·ªëi l∆∞·ª£ng giao d·ªãch theo th√°ng\n",
    "df_monthly = df.withColumn(\"Year\", year(\"Date\")) \\\n",
    "    .withColumn(\"Month\", month(\"Date\")) \\\n",
    "    .groupBy(\"Year\", \"Month\") \\\n",
    "    .agg(\n",
    "        sum(\"Volume\").alias(\"Total_Volume\"),\n",
    "        avg(\"Close\").alias(\"Avg_Price\"),\n",
    "        count(\"*\").alias(\"Trading_Days\")\n",
    "    ) \\\n",
    "    .orderBy(\"Year\", \"Month\")\n",
    "\n",
    "print(\"\\nüìä PH√ÇN T√çCH THEO TH√ÅNG\")\n",
    "print(\"=\" * 80)\n",
    "df_monthly.show(24)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. L∆∞u k·∫øt qu·∫£ ph√¢n t√≠ch\n",
    "\n",
    "# %%\n",
    "# L∆∞u k·∫øt qu·∫£ ph√¢n t√≠ch v·ªÅ HDFS\n",
    "output_path = \"hdfs://namenode:9000/analysis_results\"\n",
    "\n",
    "print(\"\\nüíæ ƒêANG L∆ØU K·∫æT QU·∫¢ PH√ÇN T√çCH...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# L∆∞u d·ªØ li·ªáu ƒë√£ ph√¢n t√≠ch\n",
    "df_analysis.write.mode(\"overwrite\").parquet(f\"{output_path}/stock_analysis\")\n",
    "print(\"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu ph√¢n t√≠ch chi ti·∫øt\")\n",
    "\n",
    "# L∆∞u ph√¢n t√≠ch theo nƒÉm\n",
    "df_yearly.write.mode(\"overwrite\").parquet(f\"{output_path}/yearly_analysis\")\n",
    "print(\"‚úÖ ƒê√£ l∆∞u ph√¢n t√≠ch theo nƒÉm\")\n",
    "\n",
    "# L∆∞u ph√¢n t√≠ch r·ªßi ro-l·ª£i nhu·∫≠n\n",
    "risk_return.write.mode(\"overwrite\").parquet(f\"{output_path}/risk_return_analysis\")\n",
    "print(\"‚úÖ ƒê√£ l∆∞u ph√¢n t√≠ch r·ªßi ro-l·ª£i nhu·∫≠n\")\n",
    "\n",
    "print(\"\\nüéâ HO√ÄN TH√ÄNH PH√ÇN T√çCH!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11. K·∫øt lu·∫≠n\n",
    "# \n",
    "# ### T√≥m t·∫Øt k·∫øt qu·∫£:\n",
    "# \n",
    "# 1. **H·ªá th·ªëng Big Data**: ƒê√£ tri·ªÉn khai th√†nh c√¥ng h·ªá th·ªëng ph√¢n t√≠ch d·ªØ li·ªáu l·ªõn v·ªõi Hadoop HDFS v√† Apache Spark\n",
    "# \n",
    "# 2. **X·ª≠ l√Ω d·ªØ li·ªáu**: X·ª≠ l√Ω h√†ng tri·ªáu d√≤ng d·ªØ li·ªáu ch·ª©ng kho√°n t·ª´ nhi·ªÅu c√¥ng ty\n",
    "# \n",
    "# 3. **Ph√¢n t√≠ch**: Th·ª±c hi·ªán ph√¢n t√≠ch xu h∆∞·ªõng, t∆∞∆°ng quan, r·ªßi ro v√† l·ª£i nhu·∫≠n\n",
    "# \n",
    "# 4. **Tr·ª±c quan h√≥a**: T·∫°o c√°c bi·ªÉu ƒë·ªì tr·ª±c quan ƒë·ªÉ h·ªó tr·ª£ ra quy·∫øt ƒë·ªãnh ƒë·∫ßu t∆∞\n",
    "# \n",
    "# ### ·ª®ng d·ª•ng th·ª±c t·∫ø:\n",
    "# - Gi√∫p nh√† ƒë·∫ßu t∆∞ ƒë∆∞a ra quy·∫øt ƒë·ªãnh th√¥ng minh\n",
    "# - Ph√°t hi·ªán xu h∆∞·ªõng v√† m·∫´u h√¨nh trong th·ªã tr∆∞·ªùng\n",
    "# - ƒê√°nh gi√° r·ªßi ro v√† c∆° h·ªôi ƒë·∫ßu t∆∞\n",
    "# - T·ªëi ∆∞u h√≥a danh m·ª•c ƒë·∫ßu t∆∞\n",
    "\n",
    "# %%\n",
    "# D·ª´ng Spark Session\n",
    "spark.stop()\n",
    "print(\"\\n‚úÖ ƒê√£ d·ª´ng Spark Session\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
